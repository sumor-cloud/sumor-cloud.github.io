# Conector llm

Una herramienta de [Sumor Cloud](https://sumor.cloud).  
[Más documentación](https://sumor.cloud)

Este es un conector llm para múltiples proveedores de servicios en la nube.

[![CI](https://github.com/sumor-cloud/llm-connector/actions/workflows/ci.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/ci.yml)
[![Test](https://github.com/sumor-cloud/llm-connector/actions/workflows/ut.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/ut.yml)
[![Cobertura](https://github.com/sumor-cloud/llm-connector/actions/workflows/coverage.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/coverage.yml)
[![Auditoría](https://github.com/sumor-cloud/llm-connector/actions/workflows/audit.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/audit.yml)

## Proveedores de servicios en la nube soportados

### OpenAI

- gpt-3.5-turbo
- gpt-4o

### Alibaba Qianwen

- qwen-turbo
- qwen-plus
- qwen-max
- qwen-max-longcontext

## Instalación

```bash
npm i @sumor/llm-connector --save
```

## Requisitos previos

### Versión de Node.JS

Se requiere Node.JS versión 16.x o superior

### Requerir módulo ES de Node.JS

Como este paquete está escrito en módulo ES, 
por favor cambie el siguiente código en su archivo `package.json`:

```json
{
  "type": "module"
}
```

## Uso

### Chat

```javascript
import Model from '@sumor/llm-connector'

const model = new Model({
  type: 'openai', // o 'qianwen'
  key: '123'
})

const response = await model.chat('gpt-3.5-turbo', [
  {
    role: 'system',
    content: 'Eres un asistente útil.'
  },
  {
    role: 'user',
    content: 'Hola'
  }
])

console.log(response)
// Salida: { role: 'asistente', content: '¡Hola, en qué puedo ayudarte hoy?' }
```

### URL de punto final de API personalizado

```javascript
import Model from '@sumor/llm-connector'

const model = new Model({
  type: 'openai',
  key: '123',
  endpoint: {
    chat: 'https://api.openai.com/v1/chat'
  }
})
```