# llm-connector

Uma Ferramenta da [Sumor Cloud](https://sumor.cloud).  
[Documentação Adicional](https://sumor.cloud)

Este é um conector llm para múltiplos provedores de nuvem.

[![CI](https://github.com/sumor-cloud/llm-connector/actions/workflows/ci.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/ci.yml)
[![Test](https://github.com/sumor-cloud/llm-connector/actions/workflows/ut.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/ut.yml)
[![Cobertura](https://github.com/sumor-cloud/llm-connector/actions/workflows/coverage.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/coverage.yml)
[![Auditoria](https://github.com/sumor-cloud/llm-connector/actions/workflows/audit.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/audit.yml)

## Provedores de Nuvem Suportados

### OpenAI

- gpt-3.5-turbo
- gpt-4o

### Alibaba Qianwen

- qwen-turbo
- qwen-plus
- qwen-max
- qwen-max-longcontext

## Instalação

```bash
npm i @sumor/llm-connector --save
```

## Pré-requisitos

### Versão Node.JS

Requer Node.JS versão 16.x ou superior

### Exigir módulo ES do Node.JS

Como este pacote é escrito em módulo ES,
por favor altere o seguinte código no seu arquivo `package.json`:

```json
{
  "type": "module"
}
```

## Uso

### Chat

```javascript
import Modelo de '@sumor/llm-connector'

const modelo = new Modelo({
  tipo: 'openai', // ou 'qianwen'
  chave: '123'
})

const resposta = await modelo.chat('gpt-3.5-turbo', [
  {
    função: 'sistema',
    conteúdo: 'Você é um assistente prestativo.'
  },
  {
    função: 'usuário',
    conteúdo: 'Olá'
  }
])

console.log(resposta)
// Saída: { função: 'assistente', conteúdo: 'Olá, como posso te ajudar hoje?' }
```

### URL de Ponto de Extremidade de API Personalizada

```javascript
import Modelo de '@sumor/llm-connector'

const modelo = new Modelo({
  tipo: 'openai',
  chave: '123',
  endpoint: {
    chat: 'https://api.openai.com/v1/chat'
  }
})
```
