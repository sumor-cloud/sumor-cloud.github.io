# llm-connector

Инструмент [Sumor Cloud](https://sumor.cloud).  
[Больше документации](https://sumor.cloud)

Это коннектор llm для нескольких облачных провайдеров.

[![CI](https://github.com/sumor-cloud/llm-connector/actions/workflows/ci.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/ci.yml)
[![Test](https://github.com/sumor-cloud/llm-connector/actions/workflows/ut.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/ut.yml)
[![Coverage](https://github.com/sumor-cloud/llm-connector/actions/workflows/coverage.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/coverage.yml)
[![Audit](https://github.com/sumor-cloud/llm-connector/actions/workflows/audit.yml/badge.svg)](https://github.com/sumor-cloud/llm-connector/actions/workflows/audit.yml)

## Установка

```bash
npm i @sumor/llm-connector --save
```

## Предварительные требования

### Версия Node.JS

Требуется версия Node.JS 16.x или выше.

### Требуется ES-модуль Node.JS

Поскольку этот пакет написан в ES-модуле,
пожалуйста, измените следующий код в своем файле `package.json`:

```json
{
  "type": "module"
}
```

## Использование

### Чат

```javascript
import Model from '@sumor/llm-connector'

const model = new Model({
  type: 'openai',
  key: '123'
})

const response = await model.chat('gpt-3.5-turbo', [
  {
    role: 'system',
    content: 'You are a helpful assistant.'
  },
  {
    role: 'user',
    content: 'Hello'
  }
])

console.log(response)
// Output: { role: 'assistant', content: 'Hello, how can I help you today?' }
```

### Пользовательский URL конечной точки API

```javascript
import Model from '@sumor/llm-connector'

const model = new Model({
  type: 'openai',
  key: '123',
  endpoint: {
    chat: 'https://api.openai.com/v1/chat'
  }
})
```
